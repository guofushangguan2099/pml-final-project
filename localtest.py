import torch
import torch.nn.functional as F
import pickle
import sys
import os
import math

# ==========================================
# 1. ç¯å¢ƒä¸è·¯å¾„è®¾ç½®
# ==========================================
# å°† src ç›®å½•åŠ å…¥è·¯å¾„ï¼Œç¡®ä¿èƒ½æ‰¾åˆ° model.py å’Œ new_preprocess.py
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

try:
    from model import Encoder, Decoder, Attention, Seq2Seq
    # å¿…é¡»å¯¼å…¥ Vocabularyï¼Œå¦åˆ™ pickle.load ä¼šæŠ¥é”™
    from new_preprocess import preprocess_text, Vocabulary
except ImportError as e:
    print("âŒ å¯¼å…¥é”™è¯¯: è¯·ç¡®ä¿ 'src' æ–‡ä»¶å¤¹ä¸‹æœ‰ model.py å’Œ new_preprocess.py")
    print(f"è¯¦ç»†é”™è¯¯: {e}")
    sys.exit(1)

# ==========================================
# 2. å…¨å±€é…ç½® (å¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´)
# ==========================================
EMBEDDING_DIM = 300
HIDDEN_DIM = 512
N_LAYERS = 1
DROPOUT = 0.5

# è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸš€ Running on: {DEVICE}")

# ==========================================
# 3. åŠ è½½æ¨¡å‹ä¸è¯è¡¨
# ==========================================
def load_model_and_vocabs():
    print("æ­£åœ¨åŠ è½½è¯è¡¨...")
    try:
        with open('data/modern_vocab.pkl', 'rb') as f:
            modern_vocab = pickle.load(f)
        with open('data/shakespearean_vocab.pkl', 'rb') as f:
            shk_vocab = pickle.load(f)
    except FileNotFoundError:
        print("âŒ é”™è¯¯: åœ¨ data/ ç›®å½•ä¸‹æ‰¾ä¸åˆ° .pkl è¯è¡¨æ–‡ä»¶ã€‚")
        sys.exit(1)

    print("æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹æ¶æ„...")
    INPUT_DIM = modern_vocab.n_words
    OUTPUT_DIM = shk_vocab.n_words

    attn = Attention(HIDDEN_DIM)
    enc = Encoder(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT)
    dec = Decoder(OUTPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT, attn)
    
    model = Seq2Seq(enc, dec, DEVICE).to(DEVICE)

    print("æ­£åœ¨åŠ è½½æ¨¡å‹æƒé‡...")
    model_path = 'saved_models/seq2seq_model.pt'
    
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ '{model_path}'")
        sys.exit(1)
        
    model.load_state_dict(torch.load(model_path, map_location=DEVICE))
    model.eval() # å…³é—­ Dropoutï¼Œè¿›å…¥è¯„ä¼°æ¨¡å¼
    
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    return model, modern_vocab, shk_vocab

# ==========================================
# 4. æ ¸å¿ƒç¿»è¯‘å‡½æ•° (Beam Search)
# ==========================================
def translate_sentence(sentence, model, modern_vocab, shk_vocab, max_len=50, beam_size=5, alpha=0.7):
    """
    ä½¿ç”¨é›†æŸæœç´¢ç¿»è¯‘å¥å­ã€‚
    :param beam_size: æŸå®½ (3-10)ã€‚è¶Šå¤§è¶Šå‡†ï¼Œä½†è¶Šæ…¢ã€‚
    :param alpha: é•¿åº¦æƒ©ç½šå› å­ (0.0-1.0)ã€‚
                  alpha è¶Šå¤§ï¼Œè¶Šé¼“åŠ±ç”Ÿæˆé•¿å¥å­ (è§£å†³ "whither?" é—®é¢˜)ã€‚
                  alpha = 0.0 è¡¨ç¤ºä¸æƒ©ç½šã€‚
    """
    model.eval()
    
    # --- 1. é¢„å¤„ç†ä¸ç¼–ç  ---
    processed_text = preprocess_text(sentence)
    tokens = [modern_vocab.word2idx.get(t, modern_vocab.word2idx['<unk>']) 
              for t in processed_text.split()]
    
    src_tensor = torch.LongTensor(tokens).unsqueeze(0).to(DEVICE)
    
    with torch.no_grad():
        encoder_outputs, hidden = model.encoder(src_tensor)
        
    # --- 2. Beam Search åˆå§‹åŒ– ---
    # ç»“æ„: (ç´¯ç§¯å¾—åˆ†, [ç”Ÿæˆçš„tokenåˆ—è¡¨], hidden_state)
    # åˆå§‹å¾—åˆ†æ˜¯ 0
    start_token = shk_vocab.word2idx['<s>']
    end_token = shk_vocab.word2idx['</s>']
    
    beams = [(0.0, [start_token], hidden)]
    
    # --- 3. è§£ç å¾ªç¯ ---
    for _ in range(max_len):
        new_beams = []
        
        for score, tokens, h in beams:
            # å¦‚æœè¯¥è·¯å¾„å·²ç»ç»“æŸ (é‡åˆ° </s>)ï¼Œç›´æ¥ä¿ç•™ï¼Œä¸ç»§ç»­å±•å¼€
            if tokens[-1] == end_token:
                new_beams.append((score, tokens, h))
                continue
            
            # è¿è¡Œ Decoder ä¸€æ­¥
            # è¾“å…¥å¿…é¡»æ˜¯ [batch=1]
            trg_tensor = torch.LongTensor([tokens[-1]]).to(DEVICE)
            
            with torch.no_grad():
                # Decoder è¿”å›: prediction, hidden, attention
                output, new_h, _ = model.decoder(trg_tensor, h, encoder_outputs)
            
            # è·å–æ¦‚ç‡åˆ†å¸ƒ (log_softmax å¾—åˆ°è´Ÿæ•°åˆ†æ•°ï¼Œè¶Šæ¥è¿‘0è¶Šå¥½)
            # output: [1, output_dim]
            log_probs = F.log_softmax(output, dim=1).squeeze(0)
            
            # é€‰å‡ºè¿™ä¸€æ­¥æ¦‚ç‡æœ€å¤§çš„ beam_size ä¸ªè¯
            topk_probs, topk_ids = log_probs.topk(beam_size)
            
            for k in range(beam_size):
                sym = topk_ids[k].item()
                prob = topk_probs[k].item()
                
                # æ›´æ–°åˆ†æ•°å’Œè·¯å¾„
                new_beams.append((score + prob, tokens + [sym], new_h))
        
        # --- 4. ç­›é€‰æœ€ä¼˜è·¯å¾„ (å¸¦é•¿åº¦æƒ©ç½š) ---
        def get_beam_score(beam_tuple):
            sc, toks, _ = beam_tuple
            # å¦‚æœåªçœ‹ scï¼ŒçŸ­å¥å­åˆ†æ•°å¤©ç„¶é«˜ (å› ä¸ºç´¯åŠ çš„è´Ÿæ•°å°‘)
            # æ‰€ä»¥é™¤ä»¥ (é•¿åº¦^alpha) æ¥è¿›è¡Œå½’ä¸€åŒ–
            length_penalty = len(toks) ** alpha
            return sc / length_penalty
            
        # æŒ‰è°ƒæ•´åçš„åˆ†æ•°æ’åºï¼Œå–å‰ beam_size ä¸ª
        new_beams.sort(key=get_beam_score, reverse=True)
        beams = new_beams[:beam_size]
        
        # å¦‚æœå‰ beam_size ä¸ªè·¯å¾„å…¨éƒ¨éƒ½ç»“æŸäº†ï¼Œé‚£å°±æå‰åœæ­¢
        if all(b[1][-1] == end_token for b in beams):
            break
            
    # --- 5. å–å‡ºç¬¬ä¸€åå¹¶è½¬æ¢å›æ–‡æœ¬ ---
    best_score, best_tokens, _ = beams[0]
    
    trg_words = []
    for idx in best_tokens:
        if idx == start_token: continue
        if idx == end_token: break
        trg_words.append(shk_vocab.idx2word[idx])
        
    return " ".join(trg_words)

# ==========================================
# 5. ä¸»ç¨‹åºå…¥å£
# ==========================================
if __name__ == "__main__":
    # 1. åŠ è½½
    model, modern_vocab, shk_vocab = load_model_and_vocabs()
    
    # 2. é¢„è®¾å¥å­æµ‹è¯•
    print("\n" + "="*40)
    print("ğŸ§ª æ ‡å‡†åŸºå‡†æµ‹è¯• (Beam Search enabled)")
    print("="*40)
    
    sentences = [
        "Where are you going?",
        "I do not think so.",
        "Can you help me?",
        "Love is a beautiful thing.",
        "He is my brother, and I love him."
    ]
    
    # å…³é”®ï¼šåœ¨è¿™é‡Œè°ƒæ•´ alpha å¯ä»¥æ”¹å˜å¥å­é•¿åº¦
    # alpha=0.6: å€¾å‘çŸ­å¥
    # alpha=1.0: å€¾å‘é•¿å¥
    ALPHA = 0.6
    BEAM_SIZE = 2

    for s in sentences:
        trans = translate_sentence(s, model, modern_vocab, shk_vocab, 
                                 beam_size=BEAM_SIZE, alpha=ALPHA)
        print(f"Modern:  {s}")
        print(f"Shakes:  {trans}")
        print("-" * 40)

    # 3. äº¤äº’æ¨¡å¼
    print("\n" + "="*40)
    print("âŒ¨ï¸  äº¤äº’æ¨¡å¼ (è¾“å…¥ 'q' é€€å‡º)")
    print(f"å½“å‰è®¾ç½®: Beam Size = {BEAM_SIZE}, Alpha = {ALPHA}")
    print("="*40)
    
    while True:
        try:
            sentence = input("\nè¯·è¾“å…¥ç°ä»£è‹±è¯­å¥å­: ")
            if sentence.lower() in ['q', 'quit', 'exit']:
                break
            
            # è¿™é‡Œä¹Ÿå¯ä»¥åŠ¨æ€è°ƒå‚æµ‹è¯•
            translation = translate_sentence(sentence, model, modern_vocab, shk_vocab, 
                                           beam_size=BEAM_SIZE, alpha=ALPHA)
            print(f">>> {translation}")
            
        except KeyboardInterrupt:
            print("\né€€å‡ºä¸­...")
            break
        except Exception as e:
            print(f"âŒ å‡ºé”™: {e}")