import pandas as pd
import re
import pickle
import os
from collections import Counter

# --- é…ç½® ---
# è¯·ç¡®ä¿ final.csv å’Œè¿™ä¸ªè„šæœ¬åœ¨åŒä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œæˆ–è€…ä¿®æ”¹è¿™é‡Œçš„è·¯å¾„
CSV_PATH = os.path.join('data', 'final.csv')
SAVE_DIR = 'data'
MIN_FREQ = 5  # å…³é”®ï¼å»æ‰åªå‡ºç°ä¸€æ¬¡çš„è¯ï¼Œå¤§å¹…é™ä½å™ªéŸ³

# --- 1. å¼ºåŠ›æ¸…æ´—å‡½æ•° ---
def clean_text(text):
    if not isinstance(text, str):
        return ""
    text = text.lower().strip()
    # å…³é”®æ”¹è¿›ï¼šæŠŠå†’å·ã€åˆ†å·ã€æ‹¬å·ã€ç ´æŠ˜å·ç­‰å…¨éƒ¨åˆ‡åˆ†å¼€
    # ä¾‹å¦‚: "king:" -> "king :"
    text = re.sub(r"([?.!,:;\"'()\-])", r" \1 ", text)
    # æŠŠå¤šä½™ç©ºæ ¼ç¼©å‡
    text = re.sub(r'[" "]+', " ", text)
    return f"<s> {text.strip()} </s>"

# --- 2. è¯æ±‡è¡¨æ„å»ºç±» (å¸¦é¢‘ç‡è¿‡æ»¤) ---
class Vocabulary:
    def __init__(self, name):
        self.name = name
        self.word2idx = {"<pad>": 0, "<s>": 1, "</s>": 2, "<unk>": 3}
        self.idx2word = {0: "<pad>", 1: "<s>", 2: "</s>", 3: "<unk>"}
        self.word_count = Counter()
        self.n_words = 4

    def build_vocab(self, sentences, min_freq=1):
        # 1. ç»Ÿè®¡æ‰€æœ‰è¯é¢‘
        print(f"Building vocab for {self.name}...")
        temp_counter = Counter()
        for sentence in sentences:
            temp_counter.update(sentence.split())
        
        # 2. åªæ·»åŠ è¶…è¿‡ min_freq çš„è¯
        for word, count in temp_counter.items():
            if count >= min_freq:
                self.word2idx[word] = self.n_words
                self.idx2word[self.n_words] = word
                self.n_words += 1
            # å¦åˆ™è¿™ä¸ªè¯ä»¥åä¼šè¢«è½¬ä¸º <unk>
        
        print(f"  Original tokens: {len(temp_counter)}")
        print(f"  Kept tokens (>= {min_freq}): {self.n_words}")
        print(f"  Filtered out: {len(temp_counter) - self.n_words + 4}")

    def numericalize(self, sentence):
        # æŠŠå¥å­è½¬æˆæ•°å­— IDï¼Œä¸åœ¨è¯è¡¨é‡Œçš„è½¬ä¸º <unk>
        return [
            self.word2idx.get(word, self.word2idx["<unk>"]) 
            for word in sentence.split()
        ]

# --- 3. ä¸»å¤„ç†æµç¨‹ ---
def run_preprocessing():
    print("--- 1. Loading Data ---")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(CSV_PATH):
        print(f"âŒ Error: '{CSV_PATH}' not found!")
        print(f"   Current working directory is: {os.getcwd()}")
        print("   Please make sure final.csv is in this folder.")
        return
    
    try:
        # å¢åŠ  encoding='utf-8' é˜²æ­¢ Windows è¯»å–æŠ¥é”™
        df = pd.read_csv(CSV_PATH, encoding='utf-8')
    except UnicodeDecodeError:
        print("âš ï¸ UTF-8 failed, trying latin-1...")
        df = pd.read_csv(CSV_PATH, encoding='latin-1')
    
    # è‡ªåŠ¨å¤„ç†åˆ—å
    if 'og' in df.columns and 't' in df.columns:
        df.rename(columns={'t': 'modern', 'og': 'shakespearean'}, inplace=True)
    elif 'Modern English' in df.columns: 
        df.rename(columns={'Modern English': 'modern', 'Shakespeare English': 'shakespearean'}, inplace=True)
    
    print(f"Loaded {len(df)} rows.")
    
    # æ¸…æ´—æ–‡æœ¬
    print("\n--- 2. Cleaning Text (Deep Clean) ---")
    df['modern_clean'] = df['modern'].apply(clean_text)
    df['shakespearean_clean'] = df['shakespearean'].apply(clean_text)
    
    print("Example Modern:", df['modern_clean'].iloc[0])
    print("Example Shakespeare:", df['shakespearean_clean'].iloc[0])
    
    # æ„å»ºè¯æ±‡è¡¨
    print("\n--- 3. Building Vocabulary ---")
    modern_vocab = Vocabulary('modern')
    shakespeare_vocab = Vocabulary('shakespearean')
    
    # ä»…ä½¿ç”¨é¢‘ç‡ >= 2 çš„è¯
    modern_vocab.build_vocab(df['modern_clean'], min_freq=MIN_FREQ)
    shakespeare_vocab.build_vocab(df['shakespearean_clean'], min_freq=MIN_FREQ)
    
    # æ•°å­—åŒ– (Numericalization)
    print("\n--- 4. Converting to Numbers ---")
    df['modern_numerical'] = df['modern_clean'].apply(modern_vocab.numericalize)
    df['shakespearean_numerical'] = df['shakespearean_clean'].apply(shakespeare_vocab.numericalize)
    


    print("\n" + "="*60)
    print("ğŸ‘€ PREVIEW: Top 5 Cleaned Sentences")
    print("="*60)
    for i in range(min(5, len(df))):
        print(f"Row {i}:")
        print(f"  [Modern] : {df['modern_clean'].iloc[i]}")
        print(f"  [Shakes] : {df['shakespearean_clean'].iloc[i]}")
        print("-" * 60)
    print("="*60 + "\n")
    # ä¿å­˜æ–‡ä»¶
    if not os.path.exists(SAVE_DIR):
        os.makedirs(SAVE_DIR)
        
    print("\n--- 5. Saving Files ---")
    df.to_pickle(os.path.join(SAVE_DIR, 'processed_data.pkl'))
    
    with open(os.path.join(SAVE_DIR, 'modern_vocab.pkl'), 'wb') as f:
        pickle.dump(modern_vocab, f)
        
    with open(os.path.join(SAVE_DIR, 'shakespearean_vocab.pkl'), 'wb') as f:
        pickle.dump(shakespeare_vocab, f)
        
    print("âœ… Done! New data is ready.")
    print(f"Modern Vocab Size: {modern_vocab.n_words}")
    print(f"Shakespeare Vocab Size: {shakespeare_vocab.n_words}")


    with open(os.path.join(SAVE_DIR, 'modern_vocab.pkl'), 'wb') as f:
        pickle.dump(modern_vocab, f)
            
    with open(os.path.join(SAVE_DIR, 'shakespearean_vocab.pkl'), 'wb') as f:
        pickle.dump(shakespeare_vocab, f)
            
    print("âœ… Done! New data is ready.")
    print(f"Modern Vocab Size: {modern_vocab.n_words}")
    print(f"Shakespeare Vocab Size: {shakespeare_vocab.n_words}")
if __name__ == "__main__":
    run_preprocessing()